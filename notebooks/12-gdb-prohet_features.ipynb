{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f'Interpreter dir: {sys.executable}')\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('../')\n",
    "    \n",
    "print(f'Working dir: {os.getcwd()}')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Ejemplo de bayessian metaparameter optimization por si quieres usarlo para buscar parametros\n",
    "def bayes_parameter_opt_lgb(X, y,\n",
    "                            init_round=15,\n",
    "                            opt_round=25, \n",
    "                            n_folds=5, \n",
    "                            random_seed=6, \n",
    "                            n_estimators=10000, \n",
    "                            learning_rate=0.02, \n",
    "                            output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction,\n",
    "                 bagging_fraction, max_depth,\n",
    "                 lambda_l1, lambda_l2,\n",
    "                 min_split_gain,\n",
    "                 min_child_weight):\n",
    "        params = {'application':'binary',\n",
    "                  'num_iterations': n_estimators, \n",
    "                  'learning_rate':learning_rate, \n",
    "                  'early_stopping_round':100, \n",
    "                  'metric':'binary'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params[\"is_unbalance\"] = True\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds,\n",
    "                           seed=random_seed,\n",
    "                           stratified=True, \n",
    "                           verbose_eval =200,\n",
    "                           metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                             'feature_fraction': (0.1, 0.9),\n",
    "                                             'bagging_fraction': (0.8, 1),\n",
    "                                             'max_depth': (5, 8.99),\n",
    "                                             'lambda_l1': (0, 5),\n",
    "                                             'lambda_l2': (0, 3),\n",
    "                                             'min_split_gain': (0.001, 0.1),\n",
    "                                             'min_child_weight': (5, 50)}, random_state=0)\n",
    "     # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "   \n",
    "     # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "     # return best parameters\n",
    "    return lgbBO#.res['max']['max_params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data with outliers remove as in previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data has outlier of std > 2 already removed\n",
    "raw = pd.read_csv(\"data/processed/clean_data.csv\", index_col=[\"Timestamp\"], parse_dates=[\"Timestamp\"])\n",
    "df = raw.rename(columns={\"is_leakage\":\"target\"})\n",
    "last_leakage_period = \"6H\" # Create target using rolling window of 6 hours\n",
    "df[\"target\"] = df[[\"target\"]].rolling(last_leakage_period).max().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize time series\n",
    "scaler = StandardScaler().fit(df.values[:, 1:])\n",
    "df.iloc[:, 1:] = scaler.transform(df.values[:, 1:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 2020 to avoid the coronavirus effect\n",
    "df_2019 = df[df.index < df.index[-14000]]\n",
    "df_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(df, test_examples=25000):\n",
    "    df_train = df[df.index < df.index[-test_examples]]\n",
    "    df_test = df[df.index > df.index[-test_examples]]\n",
    "    df_val = df_test.iloc[test_examples // 2:].copy()\n",
    "    df_test = df_test.iloc[:test_examples // 2].copy()\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = 25000\n",
    "df_train, df_test, df_val = split_datasets(df_2019)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract prophet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the non-zero features provided by prophet\n",
    "cols = [\"ds\", 'trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper',\n",
    "        'additive_terms', 'additive_terms_lower', 'additive_terms_upper',\n",
    "        'daily', 'daily_lower', 'daily_upper', 'weekly', 'weekly_lower',\n",
    "        'weekly_upper', 'yearly', 'yearly_lower', 'yearly_upper',\n",
    "        'yhat'] \n",
    "# Choosing only these ones we get pretty much the same metrics than using all the previous ones\n",
    "small_cols = [\"ds\", 'trend', 'additive_terms', 'daily', 'weekly', 'yearly', 'yhat']\n",
    "def extract_prophet_features(df, column, model, cols):\n",
    "    \"\"\"Fit a prophet model to the desired column. Return its predictions and fitter model.\"\"\"\n",
    "    pdf = df[[column]].reset_index().rename(columns={\"Timestamp\":\"ds\", column:\"y\"})\n",
    "    m =  Prophet(**model) if isinstance(model, dict) else model\n",
    "    model = m.fit(pdf)  if isinstance(model, dict) else m\n",
    "    return model, model.predict(pdf)[cols].set_index(\"ds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prpphet can be fine-tuned to get better forecastings\n",
    "prophet_params = dict(yearly_seasonality=True,\n",
    "                      weekly_seasonality=True,\n",
    "                      daily_seasonality=True,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column = \"PressureBar\"\n",
    "model_pres, press_train = extract_prophet_features(df_train, column=column, model=prophet_params, cols=small_cols)\n",
    "column = \"m3Volume\"\n",
    "model_vol, volume_train = extract_prophet_features(df_train, column=column, model=prophet_params, cols=small_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the models fit on training set to extract prophet features on the test set.\n",
    "# This is a conservative assumption, as the prophet models could be continuously trained in \n",
    "# in production to provide more accurate forecastings.\n",
    "column = \"PressureBar\"\n",
    "_, press_test = extract_prophet_features(df_test, column=column, model=model_pres, cols=small_cols)\n",
    "column = \"m3Volume\"\n",
    "_, volume_test = extract_prophet_features(df_test, column=column, model=model_vol, cols=small_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add rolling statistics (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_rolling_means(df, periods):\n",
    "    \"\"\"Add features representing rolling mean aggregation during the provided periods.\"\"\"\n",
    "    data = [df.rolling(period).mean() for period in periods]\n",
    "    df_c = df.copy()\n",
    "    for new_df, p in zip(data, periods):\n",
    "        df_c = pd.merge(df_c, new_df, left_index=True, right_index=True, how=\"inner\", suffixes=('', \"_%s\" % p))\n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\"1H\", \"2H\", \"6H\", \"12H\", \"24H\"]\n",
    "press_feats_train = add_rolling_means(press_train, periods)\n",
    "vol_feats_train = add_rolling_means(volume_train, periods)\n",
    "press_feats_test = add_rolling_means(press_test, periods)\n",
    "vol_feats_test = add_rolling_means(volume_test, periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_feats_train = press_train\n",
    "vol_feats_train = volume_train\n",
    "press_feats_test = press_test\n",
    "vol_feats_test = volume_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.merge(df_train, press_feats_train,\n",
    "                          right_index=True,\n",
    "                          left_index=True,\n",
    "                          how=\"inner\", suffixes=('', \"_press\"))\n",
    "train_features = pd.merge(train_features,\n",
    "                          vol_feats_train,\n",
    "                          right_index=True,\n",
    "                          left_index=True,\n",
    "                          how=\"inner\",\n",
    "                          suffixes=('', \"_vol\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.merge(df_test, press_feats_test,\n",
    "                          right_index=True,\n",
    "                          left_index=True,\n",
    "                          how=\"inner\", suffixes=('', \"_press\"))\n",
    "test_features = pd.merge(test_features,\n",
    "                          vol_feats_test,\n",
    "                          right_index=True,\n",
    "                          left_index=True,\n",
    "                          how=\"inner\",\n",
    "                          suffixes=('', \"_vol\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_features.drop(\"target\", axis=1)\n",
    "train_y = train_features[\"target\"]\n",
    "test_x = test_features.drop(\"target\", axis=1)\n",
    "test_y = test_features[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,classification_report\n",
    "def print_report(model):\n",
    "    y_train_pred = model.predict(train_x)\n",
    "    y_test_pred = model.predict(test_x)\n",
    "    #y_val_pred = gbm_2.predict(x_val)\n",
    "\n",
    "    print(\"TRAIN SET\")\n",
    "    print(classification_report(train_y.values.astype(int), y_train_pred.astype(int)))\n",
    "    print(\"\\nTEST SET\")\n",
    "    print(classification_report(test_y.values.astype(int), y_test_pred.astype(int)))\n",
    "    print(\"\\nTRAIN SET\")\n",
    "    print(confusion_matrix(train_y.values.astype(int), y_train_pred.astype(int)))\n",
    "    print(\"\\nTEST DATSET\")\n",
    "    print(confusion_matrix(test_y.values.astype(int), y_test_pred.astype(int)))\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This needs to be fine tuned to unbalanced classification. Mot ready to be used yet.\n",
    "opt_params = bayes_parameter_opt_lgb(train_x, train_y, init_round=5, opt_round=10,\n",
    "                                     n_folds=3,\n",
    "                                     random_seed=6,\n",
    "                                     n_estimators=60, learning_rate=0.02)\n",
    "\n",
    "def train_lgbm(train_x,train_y,test_x,test_y, params):\n",
    "    lgb_train = lgb.Dataset(train_x,train_y)\n",
    "    lgb_valid = lgb.Dataset(test_x,test_y)\n",
    "    model = lgb.train(params, lgb_train, 3000,\n",
    "                      valid_sets=[lgb_train, lgb_valid],\n",
    "                      early_stopping_rounds=10000, verbose_eval=50)\n",
    "    y_test = model.predict(test_x.values)\n",
    "    return y_test,model\n",
    "\n",
    "best_lgbm_params = opt_params.res[8][\"params\"]\n",
    "other_params = dict(objective='binary',metric='binary',\n",
    "                    n_estimators=50,\n",
    "                    scale_pos_weight=10,\n",
    "                    is_unbalance=False)\n",
    "best_lgbm_params[\"num_leaves\"] = int(best_lgbm_params[\"num_leaves\"])\n",
    "best_lgbm_params[\"max_depth\"] = int(best_lgbm_params[\"max_depth\"])\n",
    "best_lgbm_params.update(other_params)\n",
    "y_test, model = train_lgbm(train_x,train_y,test_x,test_y, best_lgbm_params)\n",
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "n_jobs = 64\n",
    "pipeline = make_pipeline(NearMiss(version=2, n_jobs=n_jobs),\n",
    "                         LogisticRegression(max_iter=500,\n",
    "                                            C=0.1,\n",
    "                                            class_weight='balanced',\n",
    "                                            n_jobs=n_jobs,\n",
    "                                            penalty='elasticnet',\n",
    "                                            solver=\"saga\",\n",
    "                                            l1_ratio=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_x.values, train_y.values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {#'pos_bagging_fraction':0.4,\n",
    "          #\"bagging_fraction\":0.5,\n",
    "   'feature_fraction': 0.3721514930979355,\n",
    "   'lambda_l1': 3.0138168803582195,\n",
    "   'lambda_l2': 1.6346495489906907,\n",
    "   'max_depth': None,\n",
    "   'min_child_weight': 1.065235087999525,\n",
    "   'min_split_gain': 0.04432113391500656,\n",
    "   'num_leaves': 42}\n",
    "gbm_2 = lgb.LGBMClassifier(objective='binary',metric='binary',\n",
    "                           n_estimators=50,\n",
    "                           bagging_fraction=0.5,\n",
    "                           scale_pos_weight=1000, # tweaking this has a direct effect on prec/recall tradeoff\n",
    "                           is_unbalance=False, **params)\n",
    "\n",
    "gbm_2 = make_pipeline(imblearn.combine.SMOTEENN(n_jobs=n_jobs),\n",
    "                      gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbm_2.fit(train_x.values, train_y.values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ray\n",
    "import tqdm\n",
    "def get_cum_metrics(y_true, y_pred):\n",
    "    metrics = defaultdict(list)\n",
    "    for i in tqdm.autonotebook.trange(1, len(x)):\n",
    "        mets = classification_report(y_true[:i], y_pred[:i], output_dict=True)\n",
    "        for k, v in mets.items():\n",
    "            if k == \"1\":\n",
    "                for ki, vi in v.items():\n",
    "                    metrics[ki].append(vi)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def calculate_metrics(i, y_true, y_pred):\n",
    "    return classification_report(y_true[:i], y_pred[:i], output_dict=True)\n",
    "\n",
    "\n",
    "y_test_pred = gbm_2.predict(test_x)\n",
    "ray.init(ignore_reinit_error=True)\n",
    "proc_ids = [calculate_metrics.remote(i, test_y.astype(int), y_test_pred.astype(int)) for i in range(1, len(test_y))]\n",
    "results = ray.get(proc_ids)\n",
    "results[0].keys()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_mets = pd.DataFrame.from_records([r[\"1\"] for r in results if \"1\" in r])\n",
    "cum_mets.iloc[:, :3].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
